# BERT 新闻主题分类

本库实现了一个基于 **Bert-base-chinese** 模型的简单新闻主题分类任务，涵盖了包括“股票”、“体育”、“旅游”等 18 个主题类别。  
该项目旨在帮助开发者快速上手 BERT 模型，尤其适合初学者，能够通过实际操作深入理解 BERT 模型的微调（fine-tuning）过程，并掌握如何利用预训练模型解决实际问题。  
项目中的代码兼容 **Python 3** 和 **Pytorch 2.3.x** 环境，方便开发者进行进一步的修改和扩展。

## 项目目录

- **data**: 存放训练数据和标签文件。
- **models**: 包含预训练的 BERT 模型和微调后的模型文件。
- **main**: 使用本项目进行训练和对比不同超参数的实验。
- **model**: 模型的结构。
- **evaluate**: 使用模型进行推理，计算准确值和损失值。
- **loader**: 负责数据处理和加载操作
- **utils**:包含了绘制表格等工具类
- **config**:配置文件

## 调整模型参数

在训练过程中，我们对 **learning_rate**、**batch_size**、**pooling_style** 等多个超参数进行了实验。通过调整这些参数，我们能够观察到不同配置对模型性能的影响。下图展示了在不同参数组合下，模型训练的准确率和损失值的对比。实验结果表明，合适的 **learning_rate** 和 **batch_size**,**pooling_style** 组合可以有效提升模型的分类性能。

<img width="540" alt="截屏2025-01-14 19 24 52" src="https://github.com/user-attachments/assets/ce8441b0-cde1-4670-9852-217fad41f404" />


从图表可以看出，较低的学习率通常能帮助模型更好地收敛，而较大的 batch_size 有时会加速训练过程，但也可能导致模型泛化能力的下降。因此，找到一个平衡点是非常关键的。

## 模型训练

下图展示了在使用最佳超参数组合下，训练过程中 **accuracy** 和 **loss** 的变化曲线。从图中可以看出，随着训练的进行，模型的准确率逐渐提高，损失值持续下降，表明模型在不断学习和优化。


![training_progress (4)](https://github.com/user-attachments/assets/337a55ee-c7b4-4fe2-946e-f6725afd2de9)

## 结果与分析

通过本项目的实验，最终模型在测试集上的准确率达到了 **91%%**。这一结果证明了 BERT 在新闻主题分类任务中的强大性能，特别是在中文文本分类问题上，预训练模型能够有效提取文本特征，从而显著提升分类效果。

### 结论

本项目展示了如何利用 BERT 模型进行新闻主题分类任务，结合了文本的上下文信息，取得了良好的效果。通过参数调优和模型微调，我们能够在实际问题中提升分类性能。未来，您可以尝试使用更大的 BERT 模型或其他预训练语言模型进一步优化分类效果。同时，可以探索数据增强、迁移学习等技术，以适应更多复杂的文本分类任务。

